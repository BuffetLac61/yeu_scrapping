# ğŸš¤ Paris â†’ Ãle dâ€™Yeu Trip Planner (Scrapy + SNCF API)

This project is part of a travel optimizer that scrapes ferry companies (Fromentine â†” Ãle dâ€™Yeu) and combines the schedules with the **SNCF API** to build optimized journeys from Paris â†’ Nantes â†’ Fromentine â†’ Ãle dâ€™Yeu.
The goal is to maximize **time spent on Ãle dâ€™Yeu** given user constraints (departure from Paris, return to Paris, optional overnight in Nantes).

---

## âš¡ Quickstart (Docker â€“ Recommended)

BEFORE Anything you will need to get your own sncf API token (it is free and available here https://www.digital.sncf.com/startup/api)

You donâ€™t need to install Python, Scrapy, or dependencies manually.
The simplest way to run this project is using the prebuilt Docker image:

```bash
docker run --rm your-dockerhub-username/yeu-voyage-planner <your_api_key> \
  --start 2025-10-16T17:15:00 \
  --end 2025-10-20T13:00:00
```

Example with a **fake key**:

```bash
docker run --rm your-dockerhub-username/yeu-voyage-planner
xxxx-xxxx-xxxx \
  --start 2025-10-16T17:15:00 \
  --end 2025-10-20T13:00:00
```

âœ… This will generate two JSON files:

* `final_voyage_plan_outbound.json` â†’ Paris â†’ Nantes â†’ Fromentine â†’ Ãle dâ€™Yeu
* `final_voyage_plan_return.json` â†’ Ãle dâ€™Yeu â†’ Fromentine â†’ Nantes â†’ Paris

ğŸ‘‰ [View DockerHub image here](https://hub.docker.com/r/your-dockerhub-username/yeu-voyage-planner)

---

## âš™ï¸ Advanced setup (manual / dev)

If you want to hack the code or run things outside Docker, youâ€™ll need to set up the Python + Scrapy environment manually.

### Requirements

* Python 3.9+ recommended
* [Scrapy](https://scrapy.org/)
* Packages listed in `requirements.txt`

Set up a virtual environment before installing dependencies:

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

## ğŸ“‚ Project setup

âš ï¸ This repo does **not** include a full Scrapy project (to keep it lightweight).
Youâ€™ll need to create a Scrapy project yourself and copy in the provided files.

### 1. Create the Scrapy project

```bash
scrapy startproject yeu
```

Project structure:

```
yeu/
â”œâ”€â”€ scrapy.cfg
â””â”€â”€ yeu/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ items.py
    â”œâ”€â”€ middlewares.py
    â”œâ”€â”€ pipelines.py
    â”œâ”€â”€ settings.py
    â””â”€â”€ spiders/
        â””â”€â”€ __init__.py
```

### 2. Copy the provided files

Overwrite or add the following files from this repo:

* `yeu/scrapy.cfg`
* `yeu/yeu/items.py`
* `yeu/yeu/middlewares.py`
* `yeu/yeu/pipelines.py`
* `yeu/yeu/settings.py`
* `yeu/yeu/spiders/yc_boat_spider.py`
* `sncf/sncf_api.py`

Final tree:

```
.
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ scrapy.cfg
â”œâ”€â”€ sncf/
â”‚   â””â”€â”€ sncf_api.py
â””â”€â”€ yeu/
    â”œâ”€â”€ items.py
    â”œâ”€â”€ middlewares.py
    â”œâ”€â”€ pipelines.py
    â”œâ”€â”€ settings.py
    â””â”€â”€ spiders/
        â””â”€â”€ yc_boat_spider.py
```

---

## ğŸƒ Usage (manual mode)

### 1. Run the spider

### 2. Run the spider
Inside yeu folder (no need to go further)
```
scrapy crawl yc_boat -a date=16/10/2025 -O boats.json
```
Example for scrapping boats on the month of October, results will be available in boats.json

This scrapes ferry timetables into `items.json`.

### 3. Use the SNCF API

Inside sncf folder:

```
python sncf_api.py <YOU SNCF API KEY> nantes fromentine_la_barre-de-monts 20251017 180000 arrival car_outbound.json
```
Example for looking for a voyage from nantes to fromentine with the arrival as close as possible to 2025 10 17 at 18H00, results will be available in car_outbound.json
---

## ğŸ“ Notes

* The Scrapy pipeline normalizes ferry data to match SNCF API format.
* `.gitignore` filters out junk files (cache, logs, exports).
* Only **essential files** are tracked here.
* The **Docker image is the easiest way** to get a working environment.

---

## ğŸ“œ License

For educational/demo purposes only. Use responsibly.

---



